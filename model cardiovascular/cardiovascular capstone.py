# -*- coding: utf-8 -*-
"""cardio 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRokDD7UodTruRFQttklqhUe9Ys3jj_I

Import Library
"""

!pip install tf2onnx

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report, confusion_matrix
import tf2onnx

"""Loading Data"""

df = pd.read_csv('cardio.csv')
df.head()

df.info()

# Baca file dengan delimiter yang benar agar kolom nya terpisah
df = pd.read_csv('cardio.csv', sep=';')

# Cek apakah kolom sudah terpisah
print(df.info())

df.head()

"""EDA"""

# Basic statistic
df.describe()

df.isnull().sum()

# Target variable distribution
print(f"\nTarget Variable Distribution:")
target_counts = df['cardio'].value_counts()
print(target_counts)
print(f"Percentage - No Disease: {target_counts[0]/len(df)*100:.1f}%")
print(f"Percentage - Disease: {target_counts[1]/len(df)*100:.1f}%")

# Create a figure and axes for subplots
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# Target distribution
axes[0,0].pie(target_counts.values, labels=['No Disease', 'Disease'], autopct='%1.1f%%', startangle=90)
axes[0,0].set_title('Disease Distribution')

# Age distribution by disease
sns.boxplot(data=df, x='cardio', y='age', ax=axes[0,1])
axes[0,1].set_title('Age Distribution by Disease Status')
axes[0,1].set_xlabel('Disease (0: No, 1: Yes)')

# Blood pressure analysis
df['bmi'] = df['weight'] / (df['height']/100)**2
sns.scatterplot(data=df, x='ap_hi', y='ap_lo', hue='cardio', alpha=0.6, ax=axes[0,2])
axes[0,2].set_title('Blood Pressure Distribution')
axes[0,2].set_xlabel('Systolic BP')
axes[0,2].set_ylabel('Diastolic BP')

# Correlation heatmap
corr_matrix = df.corr()
plt.figure(figsize=(10,8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Cholesterol vs Disease
cholesterol_disease_counts = df.groupby('cholesterol')['cardio'].value_counts().unstack(fill_value=0)
cholesterol_percentage = cholesterol_disease_counts.apply(lambda x: x / x.sum() * 100, axis=1)
cholesterol_percentage.plot(kind='bar')
plt.title('Cholesterol Level vs Disease (%)')
plt.xlabel('Cholesterol Level')
plt.ylabel('Percentage')
plt.legend(['No Disease', 'Disease'])
plt.show()

"""DATA PREPROCESSING"""

# Remove outliers (simple method)
def remove_outliers(df, column, lower_percentile=0.01, upper_percentile=0.99):
    lower_bound = df[column].quantile(lower_percentile)
    upper_bound = df[column].quantile(upper_percentile)
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Clean the data
print("Removing outliers...")
original_shape = df.shape[0]

# Remove extreme outliers for blood pressure and BMI
df = remove_outliers(df, 'ap_hi', 0.01, 0.99)
df = remove_outliers(df, 'ap_lo', 0.01, 0.99)
df = remove_outliers(df, 'bmi', 0.01, 0.99)

print(f"Removed {original_shape - df.shape[0]} outliers")
print(f"Cleaned dataset shape: {df.shape}")

# Prepare features and target
print("Preparing features and target...")
# Drop both 'cardio' (target) and 'id' (identifier)
X = df.drop(['cardio', 'id'], axis=1)
y = df['cardio']

print(f"Features shape: {X.shape}")
print(f"Target shape: {y.shape}")

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Training set: {X_train.shape}")
print(f"Test set: {X_test.shape}")

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Features scaled using StandardScaler")

"""NEURAL NETWORK MODEL"""

# Build the model
def create_nn_model(input_dim):
    # Use tf.keras instead of keras
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_dim,)),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])

    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )

    return model

# Create and display model
# The input dimension will now be 12 (13 original - 1 'id')
model = create_nn_model(X_train_scaled.shape[1])
print("Neural Network Architecture:")
model.summary()

# Add callbacks - Use tf.keras.callbacks instead of keras.callbacks
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=5,
    min_lr=0.0001
)

# Train the model
print("Training the model...")
history = model.fit(
    X_train_scaled, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

print("Model training completed!")

"""MODEL EVALUATION"""

# Make predictions
y_pred_proba = model.predict(X_test_scaled)
y_pred = (y_pred_proba > 0.5).astype(int).flatten()

# Calculate metrics - Need to import accuracy_score and roc_auc_score
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, classification_report, confusion_matrix

accuracy = accuracy_score(y_test, y_pred)
auc_score = roc_auc_score(y_test, y_pred_proba)

print(f"Test Accuracy: {accuracy:.4f}")
print(f"AUC Score: {auc_score:.4f}")

print(f"Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print(f"Confusion Matrix:")
print(cm)

# Training history
fig, ax = plt.subplots(figsize=(6, 4))

ax.plot(history.history['accuracy'], label='Training Accuracy')
ax.plot(history.history['val_accuracy'], label='Validation Accuracy')
ax.set_title('Model Accuracy')
ax.set_xlabel('Epoch')
ax.set_ylabel('Accuracy')
ax.legend()

plt.tight_layout()
plt.show()

# Loss history
fig, ax = plt.subplots(figsize=(6, 4))

ax.plot(history.history['loss'], label='Training Loss')
ax.plot(history.history['val_loss'], label='Validation Loss')
ax.set_title('Model Loss')
ax.set_xlabel('Epoch')
ax.set_ylabel('Loss')
ax.legend()

plt.tight_layout()
plt.show()

# Confusion Matrix
fig, ax = plt.subplots(figsize=(5, 4))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
ax.set_title('Confusion Matrix')
ax.set_xlabel('Predicted')
ax.set_ylabel('Actual')

plt.tight_layout()
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)

fig, ax = plt.subplots(figsize=(5.5, 5))

ax.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.3f})')
ax.plot([0, 1], [0, 1], 'k--', label='Random')
ax.set_title('ROC Curve')
ax.set_xlabel('False Positive Rate')
ax.set_ylabel('True Positive Rate')
ax.legend()

plt.tight_layout()
plt.show()

"""SAVE MODEL AND SCALER"""

# Save the model
model.save('cardio_prediction_model.h5')
print("Model saved as 'cardio_prediction_model.h5'")

# Save the scaler
import joblib
joblib.dump(scaler, 'cardio_scaler.pkl')
print("Scaler saved as 'cardio_scaler.pkl'")

# Sample prediction function
def predict_cardiovascular_disease(age, gender, height, weight, ap_hi, ap_lo,
                                 cholesterol, gluc, smoke, alco, active):
    """
    Predict cardiovascular disease probability

    Parameters:
    - age: Age in years
    - gender: 0 for female, 1 for male
    - height: Height in cm
    - weight: Weight in kg
    - ap_hi: Systolic blood pressure
    - ap_lo: Diastolic blood pressure
    - cholesterol: 1=normal, 2=above normal, 3=well above normal
    - gluc: 1=normal, 2=above normal, 3=well above normal
    - smoke: 0=no, 1=yes
    - alco: 0=no, 1=yes
    - active: 0=no, 1=yes
    """

    # Create BMI
    bmi = weight / (height/100)**2

    # Prepare input as a dictionary first to ensure column order matches training data
    # The columns should match X after dropping 'id':
    # 'age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'bmi'
    input_dict = {
        'age': age,
        'gender': gender,
        'height': height,
        'weight': weight,
        'ap_hi': ap_hi,
        'ap_lo': ap_lo,
        'cholesterol': cholesterol,
        'gluc': gluc,
        'smoke': smoke,
        'alco': alco,
        'active': active,
        'bmi': bmi
    }

    # Convert the dictionary to a Pandas DataFrame row
    input_df = pd.DataFrame([input_dict])

    # Scale the input
    # Use the scaler trained on data without the 'id' column
    input_scaled = scaler.transform(input_df)

    # Make prediction
    probability = model.predict(input_scaled)[0][0]
    prediction = "High Risk" if probability > 0.5 else "Low Risk"

    return {
        'probability': float(probability),
        'prediction': prediction,
        'risk_level': 'High' if probability > 0.7 else 'Medium' if probability > 0.3 else 'Low'
    }

# Test the prediction function
print("SAMPLE PREDICTION")
print("-"*25)

sample_result = predict_cardiovascular_disease(
    age=55, gender=1, height=175, weight=80,
    ap_hi=140, ap_lo=90, cholesterol=2, gluc=1,
    smoke=1, alco=0, active=1
)

print(f"Sample Patient Profile:")
print(f"- Age: 55, Male, Height: 175cm, Weight: 80kg")
print(f"- Blood Pressure: 140/90, Cholesterol: Above Normal")
print(f"- Smoker: Yes, Alcohol: No, Active: Yes")
print(f"\nPrediction Results:")
print(f"- Probability: {sample_result['probability']:.1%}")
print(f"- Prediction: {sample_result['prediction']}")
print(f"- Risk Level: {sample_result['risk_level']}")

# Konversi model ke format ONNX
# Wrap the Sequential model in a functional Model
inputs = tf.keras.Input(shape=(X.shape[1],), name="input")
outputs = model(inputs)
functional_model = tf.keras.Model(inputs=inputs, outputs=outputs)

spec = (tf.TensorSpec((None, X.shape[1]), tf.float32, name="input"),)

onnx_model, _ = tf2onnx.convert.from_keras(functional_model, # Use the functional_model
                                           input_signature=spec,
                                           opset=13,
                                           output_path="cardiovascular_model.onnx")

print("="*60)
print("CARDIOVASCULAR DISEASE PREDICTION SYSTEM COMPLETED!")
print("="*60)
print(f"Model Accuracy: {accuracy:.1%}")
print(f"AUC Score: {auc_score:.3f}")
print(f"Model and scaler saved successfully")
print(f"Model berhasil dikonversi ke ONNX dan disimpan sebagai cardiovascular_model.onnx")